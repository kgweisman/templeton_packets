---
title: 'SC data entry: Packets 1-3'
subtitle: 'Creating final datasets (updated with data from 2018-01-31)'
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

This is a document describing how we create the final dataset. (Last updated 2018-04-07.)

# Setup

```{r}
# load packages
library(tidyverse)

# load question key (including manual reverse-coding)
question_key <- read.csv("//Users/kweisman/Documents/Research (Stanford)/Projects/Templeton Grant/DATA WRANGLING/templeton_packets/packets123/packets123_question_key_byhand.csv")

# load data
d_all <- read.csv("//Users/kweisman/Documents/Research (Stanford)/Projects/Templeton Grant/DATA WRANGLING/templeton_packets/packets123/packets123_data.csv")[-1]
# the "-1" is to get rid of that extra column at the beginning
```

# Eliminating duplicates

Let's keep only the first entry (i.e., eliminate all double-entered "second batch" entries):

```{r}
d_tidy1 <- d_all %>%
  filter(batc == "first")

# check for duplicates
d_tidy1 %>% 
  count(subj, packet, version) %>%
  filter(n > 1)
```

Looks like this works.

# Reverse-coding

I manually added information about reverse-coding (based on information from Tanya) to our "question key" that we derived from the data-wrangling process. Let's implement reverse-coding (multiplying the numerical code by -1 whenever warranted). For now, I'm just going to keep the "numeric" version of each response:

```{r}
d_tidy2 <- d_tidy1 %>%
  select(subj, packet, version, ends_with("_num"))
names(d_tidy2) <- gsub("_num", "", names(d_tidy2))

d_tidy3 <- d_tidy2 %>% 
  gather(question_label_universal, response, -subj, -packet, -version) %>%
  left_join(question_key %>% 
              select(question_label_universal, question_text, answer_options, 
                     byhand_coding, byhand_subscale))

d_tidy4 <- d_tidy3 %>%
  # mutate(response_coded = 
  #          # if it's supposed to be reverse-coded...
  #          ifelse(byhand_coding == -1,
  #                 # if it's a dualism subscale...
  #                 ifelse(grepl("minw_", byhand_subscale) == TRUE,
  #                        # ...change 0s to 1s...
  #                        ifelse(response == 0, 
  #                               1,
  #                               # ...and 1s to 0s;
  #                               ifelse(response == 1, 
  #                                      0,
  #                                      NA)),
  #                        # otherwise, if it's a sensory subscale...
  #                        ifelse(grepl("sen_", byhand_subscale) == TRUE,
  #                               # ...multiply by -1;
  #                               response * -1,
  #                               # otherwise, throw an error
  #                               "ERROR")),
  #                 # otherwise, leave it as is
  #                 response))
  
  mutate(response_coded =
           # if it's NA...
           ifelse(is.na(byhand_coding) == TRUE,
                  # ...keep it the same;
                  response,
                  # otherwise, if it's NOT reverse-coded...
                  ifelse(byhand_coding == 1,
                         # ...keep it the same;
                         response,
                         # otherwise, if it IS reverse-coded...
                         # ...and it's in one of the minw subscales...
                         ifelse(grepl("minw_", byhand_subscale) == TRUE,
                                # ...change 0s to 1s...
                                ifelse(response == 0, 1,
                                       # ...and 1s to 0s;
                                       ifelse(response == 1, 0,
                                              NA)),
                                # otherwise, if it IS reverse-coded...
                                # ... and it's in one of the sen subscales...
                                ifelse(grepl("sen_", byhand_subscale) == TRUE,
                                       # ...multiply by -1;
                                       response * -1,
                                       "ERROR")))))

d_tidy5 <- d_tidy4 %>%
  select(subj, packet, version, byhand_subscale, 
         question_label_universal, question_text, answer_options, 
         byhand_coding, response, response_coded) %>%
  mutate(response_coded = as.numeric(as.character(response_coded))) %>%
  distinct()

glimpse(d_tidy5)
```

# Dealing with extra Thai questions on DSE

There were four on the DSE scale (`dse_07`, `dse_08`, `dse_15`, and `dse_16`), where Thai participants answered a bunch of different questions instead of just one. Let's deal with that by "crediting" Thai participants with their maximum response for any of the options for that question:

```{r}
d_dse_thai <- d_tidy5 %>%
  left_join(d_all %>% distinct(subj, ctry)) %>%
  filter(grepl("dse_07", question_label_universal) |
           grepl("dse_08", question_label_universal) |
           grepl("dse_15", question_label_universal) |
           grepl("dse_16", question_label_universal)) %>%
  mutate(question_label_universal = substr(question_label_universal, 1, 6)) %>%
  group_by(subj, question_label_universal) %>%
  top_n(1, response_coded) %>%
  distinct()

d_tidy6 <- d_tidy5 %>%
  filter(!grepl("dse_07", question_label_universal),
         !grepl("dse_08", question_label_universal),
         !grepl("dse_15", question_label_universal),
         !grepl("dse_16", question_label_universal)) %>%
  full_join(d_dse_thai) %>%
  mutate(question_text = factor(ifelse(question_label_universal %in%
                                         c("dse_07", "dse_08", 
                                           "dse_15", "dse_16"),
                                       gsub("god", "god*", 
                                            as.character(question_text)),
                                       as.character(question_text))))
```


# Eliminating people who failed attention checks

Let's see how many people failed at least one "attention check":

```{r}
failed_attn <- d_tidy6 %>%
  filter(byhand_subscale == "attn" | 
           grepl("attn", question_label_universal)) %>%
  filter(!is.na(response_coded)) %>%
  count(subj, packet, version, response_coded) %>%
  filter(response_coded == 0)
failed_attn
```

Looks like there were a total of `r nrow(failed_attn)` participants who failed at least 1 attention check. This is a lot, and it differentially affects Vanuatu. Looking at the actual attention checks, I really don't think this is a great quality control (as of 2018-04-05). Let's NOT remove their data from our dataset (at least for now).

```{r}
# d_tidy7 <- d_tidy6 %>%
#   filter(!subj %in% failed_attn$subj)

d_tidy7 <- d_tidy6
```

# Wide-form data (by question)

For some purposes, we'll want a "wide-form" dataset, where all of the data from a single participant is listed in a single ("wide") row. Let's do that here, making sure to re-add all the info we have about that participant.

```{r}
d_wide <- d_tidy7 %>%
  distinct(subj, packet, version, 
           question_label_universal, response_coded) %>%
  spread(question_label_universal, response_coded) %>%
  left_join(d_all %>%
              filter(batc == "first") %>%
              distinct(subj, packet, version,
                       demo_chur, demo_ethn, demo_maj, demo_pocc,
                       demo_rlgn, demo_sex, demo_age,
                       wher, ctry, recr, whoc)) %>%
  select(packet, version, subj, ctry, wher, recr, whoc, 
         starts_with("demo_"), starts_with("dse_"), starts_with("enco"),
         starts_with("exwl_"), starts_with("her_"), starts_with("her2_"),
         starts_with("invo_"), starts_with("meta_"), starts_with("minw_"),
         starts_with("sen_"), starts_with("sen2_"), starts_with("spev_"),
         starts_with("tat_")) %>%
  ungroup() %>%
  distinct()

glimpse(d_wide)
```

# Long-form data (by question)

For other purposes, we'll want a "long-form" dataset, where each answer to each question from each participant is on a separate row (making for "long" columns). Let's do that here.

```{r}
d_long <- d_wide %>%
  gather(question, response, 
         -c(packet, version, subj, ctry, wher, recr, whoc)) %>%
  distinct() %>%
  mutate(response = as.numeric(response))

glimpse(d_long)
```

# Long- and wide-form dataset (by subscale)

For still other purposes, we'll want both "long-form" and "wide-form" datasets by subscale summary score, rather than by question. Let's do that.

```{r}
d_long_subscale <- d_long %>%
  left_join(question_key %>% 
              select(question_label_universal, byhand_subscale) %>% 
              rename(question = question_label_universal,
                     subscale = byhand_subscale) %>%
              filter(!grepl("thai", subscale)) %>%
              mutate(subscale = factor(subscale))) %>%
  ungroup() %>%
  distinct() %>%
  filter(!is.na(response)) %>%
  group_by(packet, version, subj, ctry, wher, recr, whoc, subscale) %>%
  summarise(sum_score = sum(response, na.rm = T)) %>%
  ungroup() %>%
  distinct() %>%
  filter(!is.na(subscale)) %>%
  complete(subscale, nesting(subj, packet, version, ctry, wher, recr, whoc), 
           fill = list(sum_score = "NA")) %>%
  mutate(sum_score = as.numeric(sum_score)) %>%
  ungroup() %>%
  distinct()

glimpse(d_long_subscale)

d_long_subscale %>%
  group_by(subscale) %>%
  summarise(min = min(sum_score, na.rm = T),
            max = max(sum_score, na.rm = T)) %>%
  mutate(subscale = 
           factor(subscale,
                  levels = c("attn", 
                             "exwl", 
                             "exwl_extra",
                             "dse_01to14", 
                             # "dse_5to14_thai",
                             "dse_15to16", 
                             # "dse_15to16_thai",
                             "spev", 
                             "sen_sensory_seeking", 
                             "sen_body_awareness", 
                             "sen_trait_metamood",
                             "her2_hallucination",
                             "invo_VISQ_dialogic_speech", 
                             "invo_VISQ_inner_speech",
                             "invo_VISQ_eval_motiv_inner_speech",
                             "invo_hardy_bentall",
                             "her_posey_losch",
                             "enco_lewicki",
                             "meta_van_elk",
                             "tat_confidence",
                             "tat_positive_beliefs",
                             "tat_cognitive",
                             "tat_uncontrollability",
                             "tat_need_control",
                             "minw_mental_states",
                             "minw_life_events",
                             "minw_inanimate",
                             "minw_selves_souls_world",
                             "minw_epistemic")))
```

```{r}
d_wide_subscale <- d_long_subscale %>%
  spread(subscale, sum_score) %>%
  distinct()

glimpse(d_wide_subscale)
```

# Saving off files

```{r}
write_csv(d_wide, "./packets123_data_byquestion_wide.csv")
write_csv(d_wide_subscale, "./packets123_data_bysubscale_wide.csv")
write_csv(d_long, "./packets123_data_byquestion_long.csv")
write_csv(d_long_subscale, "./packets123_data_bysubscale_long.csv")
```


